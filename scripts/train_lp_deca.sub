#!/bin/bash
#SBATCH --job-name=lp_deca
#SBATCH --nodes=1
#SBATCH --cpus-per-task=1
#SBATCH --gres=gpu:2080ti:1
#SBATCH --mem=32GB
#SBATCH --time=128:00:00
#SBATCH --partition=default_gpu

cd $HOME/automl-for-low-precision-training; 
python train_lp_deca.py --arch resnet18 --transform deca_train  --epo 10 --bs 32 --lr 0.001 --data_dir datasets/my_deca